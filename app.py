import os
import json
import streamlit as st
from openai import OpenAI, APIConnectionError  # å‡è®¾æ‚¨ä½¿ç”¨çš„æ˜¯OpenAI

# ---------- ä»£ç†ï¼ˆæœ¬åœ°ç”¨ï¼›äº‘ç«¯ç•™ç©ºï¼‰ ----------
PROXY_URL = os.getenv("PROXY_URL", "")

# ---------- OpenAI å®¢æˆ·ç«¯ ----------
# (æ‚¨çš„OpenAIå®¢æˆ·ç«¯åˆå§‹åŒ–ä»£ç ä¿æŒä¸å˜)
if PROXY_URL:
    from openai import RequestsTransport

    client = OpenAI(
        api_key=os.getenv("OPENAI_API_KEY"),
        transport=RequestsTransport(
            proxies={"http": PROXY_URL, "https": PROXY_URL}
        ),
        timeout=60,
        max_retries=3,
    )
else:
    client = OpenAI(
        api_key=os.getenv("OPENAI_API_KEY"),
        timeout=60,
        max_retries=3,
    )

# ---------- Streamlit é¡µé¢ ----------
st.set_page_config(page_title="äººç”Ÿè„šæœ¬Â·åŠ¨æ€æé—®", layout="centered")
st.title("äººç”Ÿè„šæœ¬æ¢ç´¢ Demo ğŸŒ€")

# === åŠ è½½æ‚¨çš„ JSON Prompt å®šä¹‰ ===
# ç¡®ä¿SYSTEM_PROMPTæ˜¯æ­£ç¡®çš„ã€åŒ…å«æ‰€æœ‰é˜¶æ®µå®šä¹‰çš„JSONå­—ç¬¦ä¸²
SYSTEM_PROMPT_JSON_STRING = r"""
{
  "prompt_definition": {
    "overall_goal": "ä½œä¸ºäººç”Ÿè„šæœ¬æ¢ç´¢AIåŠ©æ‰‹ï¼Œä¸ç”¨æˆ·è¿›è¡Œå¤šè½®å¯¹è¯ï¼Œä¸¥æ ¼æŒ‰é¡ºåºå¼•å¯¼ç”¨æˆ·å›ç­”å®Œæ‰€æœ‰é¢„è®¾é—®é¢˜ï¼Œå¹¶åœ¨æœ€åç›´æ¥ç”Ÿæˆåˆæ­¥æ¢ç´¢æŠ¥å‘Šã€‚æ•´ä¸ªè¿‡ç¨‹éœ€å‹å¥½ã€è‡ªç„¶ï¼Œå¹¶ç¡®ä¿å¯¹è¯ä¸åç¦»ä¸»é¢˜ã€‚",
    "input_variables": [
      { "name": "interaction_phase", "description": "å½“å‰äº¤äº’é˜¶æ®µ ('initial_greeting', 'conversation_turn', 'final_report')" },
      { "name": "current_question_index", "description": "å½“å‰é—®é¢˜ç´¢å¼• (ä»1å¼€å§‹è®¡æ•°ï¼Œä»…åœ¨ 'conversation_turn' é˜¶æ®µéœ€è¦)" },
      { "name": "user_input", "description": "ç”¨æˆ·çš„ä¸Šä¸€å¥è¾“å…¥ (åœ¨ 'conversation_turn' å’Œ 'final_report' é˜¶æ®µéœ€è¦)" },
      { "name": "conversation_history", "description": "æœ€è¿‘å‡ è½®çš„å¯¹è¯å†å² (ç”¨äº 'conversation_turn' åˆ¤æ–­è·‘é¢˜)" },
      { "name": "full_conversation_transcript", "description": "å®Œæ•´çš„å¯¹è¯è®°å½• (ä»…åœ¨ 'final_report' é˜¶æ®µéœ€è¦)" },
      { "name": "total_questions", "description": "é¢„è®¾é—®é¢˜çš„æ€»æ•°" },
      { "name": "estimated_time", "description": "é¢„è®¡å®Œæˆå¯¹è¯æ‰€éœ€æ—¶é—´ (ä¾‹å¦‚ '5-8åˆ†é’Ÿ')" }
    ],
    "question_list": [
      "åœ¨æ‚¨é•¿å¤§çš„è¿‡ç¨‹ä¸­ï¼Œå®¶é‡Œï¼ˆæˆ–è€…å¯¹æ‚¨å½±å“æœ€å¤§çš„äººï¼‰ç»å¸¸å¼ºè°ƒçš„â€˜è§„çŸ©â€™æˆ–è€…â€˜æœŸæœ›â€™æ˜¯ä»€ä¹ˆï¼Ÿï¼ˆæ¯”å¦‚ï¼Œè¦å¬è¯ã€è¦ç‹¬ç«‹ã€è¦è®©å®¶äººéª„å‚²ç­‰ç­‰ï¼‰",
      "å›æƒ³ä¸€ä¸‹æ‚¨å¤§æ¦‚ä¸Šå°å­¦çš„æ—¶å€™ï¼Œæ‚¨è§‰å¾—è‡ªå·±æ˜¯ä¸ªä»€ä¹ˆæ ·çš„å­©å­ï¼Ÿï¼ˆå¯ä»¥è¯´è¯´æ€§æ ¼ã€ä¼˜ç‚¹æˆ–ç¼ºç‚¹ï¼‰",
      "é‚£æ—¶å€™ï¼Œæ‚¨æ„Ÿè§‰å‘¨å›´çš„å¤§äººï¼ˆæ¯”å¦‚çˆ¶æ¯ã€è€å¸ˆï¼‰æ€ä¹ˆæ ·ï¼Ÿä»–ä»¬å¯¹æ‚¨å¥½å—ï¼Ÿ",
      "æœ‰æ²¡æœ‰ä»€ä¹ˆäº‹æƒ…ï¼Œæ˜¯æ‚¨ä»å°å°±è§‰å¾—â€˜åƒä¸‡ä¸èƒ½åšâ€™æˆ–è€…â€˜æœ€å¥½ä¸è¦æâ€™çš„ï¼Ÿï¼ˆæ¯”å¦‚ï¼šä¸èƒ½çŠ¯é”™ã€ä¸èƒ½è½¯å¼±ã€ä¸èƒ½æ¯”åˆ«äººå·®ã€ä¸èƒ½è¡¨è¾¾éœ€è¦ï¼Ÿï¼‰",
      "ä¸ºäº†å¾—åˆ°è¡¨æ‰¬æˆ–è€…é¿å…éº»çƒ¦ï¼Œæ‚¨è§‰å¾—å¿…é¡»åšåˆ°å“ªäº›äº‹æƒ…ï¼Ÿï¼ˆæ¯”å¦‚ï¼šå¿…é¡»åŠªåŠ›ã€å¿…é¡»æ‡‚äº‹ã€å¿…é¡»è®¨äººå–œæ¬¢ï¼Ÿï¼‰",
      "å°æ—¶å€™ï¼Œæ‚¨æœ€å–œæ¬¢å¬çš„æ•…äº‹ã€çœ‹çš„åŠ¨ç”»ç‰‡æˆ–è€…å´‡æ‹œçš„è‹±é›„äººç‰©æ˜¯è°ï¼Ÿèƒ½è¯´è¯´ä¸ºä»€ä¹ˆå–œæ¬¢å—ï¼Ÿ",
      "ç°åœ¨çš„ç”Ÿæ´»æˆ–å·¥ä½œä¸­ï¼Œæœ‰æ²¡æœ‰ä¸€äº›è®©æ‚¨æ„Ÿè§‰ä¸å¤ªèˆ’æœï¼Œä½†åˆå¥½åƒæ€»æ˜¯åå¤å‘ç”Ÿçš„æƒ…å†µï¼Ÿï¼ˆæ¯”å¦‚ï¼šæ€»æ˜¯åƒåŠ›ä¸è®¨å¥½ã€æ€»è¢«è¯¯è§£ã€æ€»æ˜¯ä¸æ•¢æ‹’ç»ï¼Ÿï¼‰",
      "å¦‚æœç”¨ä¸€ä¸ªè¯æˆ–ä¸€ç§æ„Ÿè§‰æ¥å½¢å®¹æ‚¨çš„äººç”Ÿåˆ°ç›®å‰ä¸ºæ­¢çš„ä¸»åŸºè°ƒï¼Œä¼šæ˜¯ä»€ä¹ˆï¼Ÿï¼ˆæ¯”å¦‚ï¼šå¥‹æ–—ã€å¹¸è¿ã€å¹³æ·¡ã€æŒ£æ‰ï¼Ÿï¼‰",
      "ä¸è€ƒè™‘ç°å®é™åˆ¶ï¼Œæ‚¨å†…å¿ƒæ·±å¤„å·å·å¸Œæœ›è‡ªå·±çš„äººç”Ÿæœ€ç»ˆä¼šæ˜¯ä¸€ä¸ªä»€ä¹ˆæ ·çš„ç»“å±€ï¼Ÿ"
    ],
    "rules_and_logic": {
      "phase_initial_greeting": {
        "condition": "`interaction_phase` == 'initial_greeting'",
        "action": "è¾“å‡ºå›ºå®šé—®å€™è¯­ï¼ŒåŒ…å«é—®é¢˜æ€»æ•°å’Œé¢„è®¡æ—¶é—´ï¼Œå¹¶æå‡ºç¬¬ä¸€ä¸ªé—®é¢˜ï¼ˆå³ `question_list` ä¸­ç´¢å¼•ä¸º0çš„é—®é¢˜ï¼Œå› ä¸º`current_question_index`ä»1å¼€å§‹è®¡æ•°ï¼‰ã€‚æ ¼å¼å¦‚ä¸‹ï¼š'æ‚¨å¥½ï¼æˆ‘æ˜¯äººç”Ÿè„šæœ¬æ¢ç´¢åŠ©æ‰‹ã€‚å¾ˆé«˜å…´èƒ½å’Œæ‚¨èŠä¸€èŠã€‚æ¥ä¸‹æ¥æˆ‘ä¼šé—®æ‚¨ {{total_questions}} ä¸ªé—®é¢˜ï¼Œå¤§æ¦‚éœ€è¦ {{estimated_time}} å·¦å³ã€‚æˆ‘ä»¬å¼€å§‹å§ï¼Ÿç¬¬ä¸€ä¸ªé—®é¢˜æ˜¯ï¼š[è¿™é‡Œæ˜¯ question_list[0] çš„æ–‡æœ¬]'",
        "output_format": "çº¯æ–‡æœ¬"
      },
      "phase_conversation_turn": {
        "condition": "`interaction_phase` == 'conversation_turn'",
        "sub_rules": [
          "è§„åˆ™1 (ä¸¥æ ¼æŒ‰åºæé—®): æ ¹æ® `current_question_index` ä» `question_list` æ‰¾åˆ°å½“å‰è¦é—®çš„é—®é¢˜ï¼ˆåˆ—è¡¨ç´¢å¼•ä¸º `current_question_index - 1`ï¼‰ã€‚",
          { "rule_name": "è§„åˆ™2 (åˆ¤æ–­è·‘é¢˜ä¸æŸ”æ€§æ‹‰å›)", "logic": "åˆ†æ `user_input` æ˜¯å¦å›åº”äº†ä¸Šä¸€ä¸ªé—®é¢˜ã€‚å¦‚æœç”¨æˆ·æå‡ºæ— å…³é—®é¢˜æˆ–æ˜æ˜¾åç¦»ä¸»é¢˜ï¼š a. ç”¨ä¸€ä¸¤å¥éå¸¸ç®€çŸ­ã€ä¸­æ€§çš„è¯å›åº”ï¼Œç¦æ­¢æ·±å…¥æ¢è®¨ï¼› b. ç„¶åè‡ªç„¶è¿‡æ¸¡å›åŸæ¥çš„é—®é¢˜ï¼› c. æœ€åæ¸…æ™°é‡å¤åŸå§‹é—®é¢˜ã€‚" },
          "è§„åˆ™3 (å¤„ç†æ¨¡ç³Šå›ç­”): å¦‚æœå›ç­”è¿‡çŸ­ï¼Œä»…å¯è¿½é—®ä¸€æ¬¡â€œèƒ½ç¨å¾®å…·ä½“ä¸€ç‚¹è¯´è¯´å—ï¼Ÿâ€ã€‚",
          "è§„åˆ™4 (ç¡®è®¤ä¸æé—®): ç”¨æˆ·å›ç­”åï¼ˆä¸”éæœ€åä¸€é¢˜ï¼‰ï¼Œç”¨ç®€çŸ­ç¡®è®¤è¯­ï¼Œå†æå‡ºä¸‹ä¸€é¢˜ã€‚",
          "è§„åˆ™5 (ä¸å›ç­”æ— å…³é—®é¢˜): è‹¥ç”¨æˆ·é—® AI è‡ªèº«æˆ–æ— å…³è¯é¢˜ï¼Œè§†ä¸ºè·‘é¢˜ï¼Œæ‰§è¡Œè§„åˆ™2ã€‚",
          "è§„åˆ™6 (è¿›å…¥æŠ¥å‘Šé˜¶æ®µåˆ¤æ–­): æœ€åä¸€é¢˜ç­”å®Œåï¼Œä¸‹ä¸€æ¬¡ `interaction_phase` å˜ä¸º `final_report`ã€‚"
        ],
        "action": "ä¾æ®å­è§„åˆ™ç”Ÿæˆå›åº”ã€‚",
        "output_format": "çº¯æ–‡æœ¬"
      },
      "phase_final_report": {
        "condition": "`interaction_phase` == 'final_report'",
        "sub_rules": [
          "è§„åˆ™1 (åŸºäºè®°å½•): æŠ¥å‘Šåªèƒ½åŸºäº `full_conversation_transcript`ã€‚",
          "è§„åˆ™2 (ç»“åˆç†è®º): å°†å›ç­”ä¸ã€Šäººç”Ÿè„šæœ¬ã€‹æ¦‚å¿µå…³è”ï¼Œä½¿ç”¨â€œä¸ç¡®å®šâ€ç”¨è¯­ã€‚",
          "è§„åˆ™3 (ç»“æ„åŒ–æŠ¥å‘Š): å¼•è¨€ã€å›ç­”æ‘˜è¦ã€è„šæœ¬å…ƒç´ åˆ†æã€ç»“è¯­ã€‚",
          "è§„åˆ™4 (ä¸­æ€§å®¢è§‚): ä¸è¯„åˆ¤ã€‚",
          "è§„åˆ™5 (ç®€æ´æ˜äº†): æŠ“è¦ç‚¹ã€‚",
          "è§„åˆ™6 (ç›´æ¥è¾“å‡º): ä»…è¾“å‡ºæŠ¥å‘Š Markdownï¼Œæœ¬èº«ä¸è¯´å¤šä½™è¯ã€‚"
        ],
        "action": "ç”Ÿæˆ Markdown æ ¼å¼åˆæ­¥æŠ¥å‘Šã€‚",
        "output_format": "Markdownæ–‡æœ¬"
      }
    },
    "task_description": "æ ¹æ® `interaction_phase` ç­‰å˜é‡ï¼Œä¸¥æ ¼éµå¾ªè§„åˆ™ç”Ÿæˆè¾“å‡ºã€‚"
  }
}
"""
PROMPT_CONFIG = json.loads(SYSTEM_PROMPT_JSON_STRING)["prompt_definition"]
QUESTION_LIST = PROMPT_CONFIG["question_list"]
TOTAL_QUESTIONS = len(QUESTION_LIST)
ESTIMATED_TIME = "5-8åˆ†é’Ÿ"  # æ‚¨å¯ä»¥æ ¹æ®é—®é¢˜æ•°é‡è°ƒæ•´

# ---------- åˆå§‹åŒ–ä¼šè¯çŠ¶æ€ ----------
if "history" not in st.session_state:
    st.session_state.history = []  # å­˜æ”¾ {"role": "user/assistant", "content": "..."}
if "interaction_phase" not in st.session_state:
    st.session_state.interaction_phase = "initial_greeting"
if "current_question_index" not in st.session_state:
    # current_question_index: 1 è¡¨ç¤ºç¬¬ä¸€ä¸ªé—®é¢˜, ..., TOTAL_QUESTIONS è¡¨ç¤ºæœ€åä¸€ä¸ªé—®é¢˜
    st.session_state.current_question_index = 1
if "report_generated" not in st.session_state:
    st.session_state.report_generated = False


# ---------- æ ¸å¿ƒå‡½æ•°ï¼šè°ƒç”¨LLMå¹¶å¤„ç†å›å¤ ----------
def get_ai_response(phase, user_input_text=None, history_for_prompt=None, full_transcript=None):
    """æ ¹æ®å½“å‰é˜¶æ®µå’Œè¾“å…¥ï¼Œæ„å»ºå‘é€ç»™LLMçš„promptå¹¶è·å–å›å¤"""

    # 1. æ„å»ºä¼ é€’ç»™LLMçš„ messages (åŒ…å« system prompt å’Œå¯¹è¯å†å²/ä¸Šä¸‹æ–‡)
    #    è¿™é‡Œçš„å…³é”®æ˜¯ï¼Œsystem_promptä¸å†æ˜¯æ•´ä¸ªå¤§JSONï¼Œè€Œæ˜¯æ ¹æ®å½“å‰é˜¶æ®µåŠ¨æ€ç”Ÿæˆçš„ã€æ›´ç›´æ¥çš„æŒ‡ä»¤ã€‚
    #    æˆ‘ä»¬å°†JSONä¸­çš„è§„åˆ™â€œç¿»è¯‘â€æˆç»™LLMçš„ç›´æ¥æŒ‡ä»¤ã€‚

    active_system_prompt = f"ä½ æ˜¯ä¸€ä¸ªäººç”Ÿè„šæœ¬æ¢ç´¢AIåŠ©æ‰‹ã€‚{PROMPT_CONFIG['overall_goal']}\n"
    active_system_prompt += f"å½“å‰äº¤äº’é˜¶æ®µæ˜¯: {phase}\n"
    active_system_prompt += f"å…±æœ‰ {TOTAL_QUESTIONS} ä¸ªé¢„è®¾é—®é¢˜ã€‚\n"

    if phase == "initial_greeting":
        active_system_prompt += PROMPT_CONFIG["rules_and_logic"]["phase_initial_greeting"]["action"].replace(
            "{{total_questions}}", str(TOTAL_QUESTIONS)
        ).replace(
            "{{estimated_time}}", ESTIMATED_TIME
        ).replace(
            "[è¿™é‡Œæ˜¯ question_list[0] çš„æ–‡æœ¬]", QUESTION_LIST[0]  # å‡è®¾ç¬¬ä¸€ä¸ªé—®é¢˜ç´¢å¼•æ˜¯0
        )
        active_system_prompt += "\nè¯·ä¸¥æ ¼æŒ‰ç…§ä¸Šè¿°æ ¼å¼è¾“å‡ºé—®å€™å’Œç¬¬ä¸€ä¸ªé—®é¢˜ã€‚"

    elif phase == "conversation_turn":
        current_q_text = QUESTION_LIST[st.session_state.current_question_index - 1]
        active_system_prompt += f"å½“å‰æ­£åœ¨å¤„ç†ç¬¬ {st.session_state.current_question_index} ä¸ªé—®é¢˜ã€‚\n"
        active_system_prompt += f"å½“å‰é—®é¢˜æ˜¯ï¼šâ€œ{current_q_text}â€\n"
        if user_input_text:
            active_system_prompt += f"ç”¨æˆ·çš„æœ€æ–°å›ç­”æ˜¯ï¼šâ€œ{user_input_text}â€\n"
        if history_for_prompt:
            active_system_prompt += f"æœ€è¿‘çš„å¯¹è¯å†å²å¦‚ä¸‹ï¼š\n{history_for_prompt}\n"

        active_system_prompt += "è¯·ä¸¥æ ¼éµå¾ªä»¥ä¸‹å¯¹è¯è§„åˆ™ï¼š\n"
        active_system_prompt += "- " + PROMPT_CONFIG["rules_and_logic"]["phase_conversation_turn"]["sub_rules"][
            0] + "\n"  # è§„åˆ™1
        # è§„åˆ™2 (æŸ”æ€§æ‹‰å›) - éœ€è¦æ›´è¯¦ç»†çš„æŒ‡ä»¤ç»™LLM
        pull_back_logic = PROMPT_CONFIG["rules_and_logic"]["phase_conversation_turn"]["sub_rules"][1]["logic"]
        active_system_prompt += f"- {pull_back_logic.replace('[é‡å¤ä¸Šä¸€ä¸ªé—®é¢˜]', f'â€œ{current_q_text}â€')}\n"
        active_system_prompt += "- " + PROMPT_CONFIG["rules_and_logic"]["phase_conversation_turn"]["sub_rules"][
            2] + "\n"  # è§„åˆ™3
        active_system_prompt += "- " + PROMPT_CONFIG["rules_and_logic"]["phase_conversation_turn"]["sub_rules"][
            3] + "\n"  # è§„åˆ™4
        if st.session_state.current_question_index < TOTAL_QUESTIONS:
            next_q_text = QUESTION_LIST[st.session_state.current_question_index]  # ä¸‹ä¸€ä¸ªé—®é¢˜çš„æ–‡æœ¬
            active_system_prompt = active_system_prompt.replace("[ä¸‹ä¸€ä¸ªé—®é¢˜]", f"â€œ{next_q_text}â€")

        active_system_prompt += "\nä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®ç”¨æˆ·çš„å›ç­”å’Œä¸Šè¿°è§„åˆ™ï¼Œç”Ÿæˆä½ çš„ä¸‹ä¸€å¥å›åº”ã€‚"
        active_system_prompt += "å¦‚æœç”¨æˆ·è·‘é¢˜ï¼ŒæŒ‰è§„åˆ™2æŸ”æ€§æ‹‰å›ï¼›å¦‚æœç”¨æˆ·å›ç­”æ¨¡ç³Šï¼ŒæŒ‰è§„åˆ™3è¿½é—®ï¼›å¦‚æœç”¨æˆ·æ­£å¸¸å›ç­”ï¼ŒæŒ‰è§„åˆ™4ç¡®è®¤å¹¶æå‡ºä¸‹ä¸€ä¸ªé—®é¢˜ã€‚"
        active_system_prompt += "å¦‚æœå½“å‰æ˜¯æœ€åä¸€ä¸ªé—®é¢˜ï¼Œå¹¶ä¸”ç”¨æˆ·å›ç­”äº†ï¼Œè¯·åªåšç®€çŸ­ç¡®è®¤ï¼Œä¸è¦æâ€œä¸‹ä¸€ä¸ªé—®é¢˜â€ã€‚"


    elif phase == "final_report":
        active_system_prompt += "ç°åœ¨æ‰€æœ‰é—®é¢˜å·²å›ç­”å®Œæ¯•ã€‚ç”¨æˆ·çš„å®Œæ•´å¯¹è¯è®°å½•å¦‚ä¸‹ï¼š\n"
        active_system_prompt += f"{full_transcript}\n"
        active_system_prompt += "è¯·ä¸¥æ ¼éµå¾ªä»¥ä¸‹æŠ¥å‘Šç”Ÿæˆè§„åˆ™ï¼š\n"
        for rule in PROMPT_CONFIG["rules_and_logic"]["phase_final_report"]["sub_rules"]:
            active_system_prompt += f"- {rule}\n"
        active_system_prompt += "\nä½ çš„ä»»åŠ¡æ˜¯ç›´æ¥ç”ŸæˆMarkdownæ ¼å¼çš„åˆæ­¥äººç”Ÿè„šæœ¬æ¢ç´¢æŠ¥å‘Šï¼Œä¸è¦æ·»åŠ ä»»ä½•å…¶ä»–å¯¹è¯æ€§æ–‡å­—ã€‚"

    # 2. æ„å»ºmessagesåˆ—è¡¨
    messages_for_llm = [{"role": "system", "content": active_system_prompt}]
    # åœ¨conversation_turné˜¶æ®µï¼Œå¯ä»¥è€ƒè™‘åŠ å…¥æœ€è¿‘å‡ è½®çš„user/assistantå†å²ï¼Œä½†ä¸åŠ å…¥system promptä¸­çš„å†å²
    if phase == "conversation_turn" and st.session_state.history:
        # åªæ·»åŠ æœ€è¿‘çš„å‡ è½®å¯¹è¯å†å²ä½œä¸ºä¸Šä¸‹æ–‡ï¼Œé¿å…è¿‡é•¿
        for msg in st.session_state.history[-4:]:  # ä¾‹å¦‚æœ€è¿‘4æ¡
            if msg["role"] != "system":  # é¿å…é‡å¤æ·»åŠ system
                messages_for_llm.append(msg)
        if user_input_text:  # ç¡®ä¿å½“å‰ç”¨æˆ·è¾“å…¥ä¹ŸåŒ…å«åœ¨å†…ï¼ˆå¦‚æœé€‚ç”¨ï¼‰
            # å¦‚æœhistoryå·²ç»åŒ…å«äº†å½“å‰user_inputï¼Œåˆ™ä¸éœ€è¦é‡å¤æ·»åŠ 
            if not (messages_for_llm and messages_for_llm[-1]["role"] == "user" and messages_for_llm[-1][
                "content"] == user_input_text):
                messages_for_llm.append({"role": "user", "content": user_input_text})

    # st.write("DEBUG: Prompt to LLM:") # è°ƒè¯•æ—¶å¯ä»¥å–æ¶ˆæ³¨é‡Š
    # st.text(messages_for_llm)

    try:
        resp = client.chat.completions.create(
            model="gpt-4o-mini",  # æˆ–è€…æ‚¨é€‰æ‹©çš„æ¨¡å‹
            messages=messages_for_llm,
            temperature=0.5,  # é™ä½ä¸€ç‚¹éšæœºæ€§ï¼Œä½¿å…¶æ›´éµå¾ªæŒ‡ä»¤
        )
        ai_content = resp.choices[0].message.content.strip()
        return ai_content
    except APIConnectionError as e:
        st.error("ğŸš§ æ— æ³•è¿æ¥ OpenAIï¼Œæ£€æŸ¥ç½‘ç»œ/ä»£ç†åé‡è¯•ã€‚\n\n" + str(e))
        return None
    except Exception as e:
        st.error(f"è°ƒç”¨LLMæ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
        return None


# ---------- ä¸»æµç¨‹æ§åˆ¶ ----------

# 1. å¤„ç†åˆå§‹é—®å€™ (å¦‚æœè¿˜æ²¡æœ‰å†å²è®°å½•ï¼Œæˆ–è€…æ˜ç¡®æ˜¯initial_greetingé˜¶æ®µ)
if not st.session_state.history and st.session_state.interaction_phase == "initial_greeting":
    with st.spinner("AIæ­£åœ¨å‡†å¤‡å¼€åœºç™½..."):
        initial_greeting_text = get_ai_response(phase="initial_greeting")
    if initial_greeting_text:
        st.session_state.history.append({"role": "assistant", "content": initial_greeting_text})
        st.session_state.interaction_phase = "conversation_turn"  # è¿›å…¥å¯¹è¯é˜¶æ®µ
        st.session_state.current_question_index = 1  # AIé—®äº†ç¬¬ä¸€ä¸ªé—®é¢˜
        st.rerun()

# 2. æ˜¾ç¤ºèŠå¤©å†å²
for msg in st.session_state.history:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# 3. è·å–ç”¨æˆ·è¾“å…¥
if not st.session_state.report_generated and st.session_state.interaction_phase == "conversation_turn":
    user_text = st.chat_input("è¯·è¾“å…¥æ‚¨çš„å›ç­”â€¦")

    if user_text:
        # å°†ç”¨æˆ·å›å¤æ·»åŠ åˆ°å†å²
        st.session_state.history.append({"role": "user", "content": user_text})
        # ç«‹åˆ»æ˜¾ç¤ºç”¨æˆ·å›å¤
        with st.chat_message("user"):
            st.markdown(user_text)

        # å‡†å¤‡è°ƒç”¨LLMçš„ä¸Šä¸‹æ–‡
        # history_for_prompt = "\n".join([f"{m['role']}: {m['content']}" for m in st.session_state.history[-5:]]) # æœ€è¿‘5æ¡

        # è°ƒç”¨LLMè·å–AIçš„ä¸‹ä¸€å¥è¯
        with st.spinner("AIæ­£åœ¨æ€è€ƒ..."):
            # æ³¨æ„ï¼šè¿™é‡Œä¼ é€’ç»™ get_ai_response çš„ history_for_prompt æ˜¯ä¸ºäº†è®© system prompt çŸ¥é“æœ€è¿‘çš„å¯¹è¯
            # è€Œ messages_for_llm åˆ—è¡¨ä¸­çš„å†å²æ˜¯æ›´ç›´æ¥çš„ä¸Šä¸‹æ–‡
            ai_response_text = get_ai_response(
                phase="conversation_turn",
                user_input_text=user_text
                # history_for_prompt=history_for_prompt # å¦‚æœsystem promptéœ€è¦æ ¼å¼åŒ–çš„å†å²
            )

        if ai_response_text:
            st.session_state.history.append({"role": "assistant", "content": ai_response_text})

            # åˆ¤æ–­æ˜¯å¦æ‰€æœ‰é—®é¢˜éƒ½å·²é—®å®Œï¼ˆåŸºäºAIçš„å›å¤æˆ–è®¡æ•°ï¼‰
            # è¿™é‡Œçš„é€»è¾‘éœ€è¦éå¸¸å°å¿ƒï¼ŒAIçš„å›å¤å¯èƒ½ä¸æ˜¯ç›´æ¥çš„ä¸‹ä¸€ä¸ªé—®é¢˜æ–‡æœ¬
            # ä¸€ä¸ªæ›´ç¨³å¦¥çš„æ–¹å¼æ˜¯ä¸¥æ ¼ç®¡ç† current_question_index
            # å‡è®¾AIçš„å›å¤å¦‚æœæ˜¯æé—®ï¼Œä¼šåŒ…å«é—®é¢˜å†…å®¹ï¼›å¦‚æœæ˜¯ç¡®è®¤ï¼Œåˆ™æˆ‘ä»¬æ¨è¿›index

            # ç®€åŒ–çš„æ¨è¿›é€»è¾‘ï¼šåªè¦AIå›å¤äº†ï¼Œæˆ‘ä»¬å°±è®¤ä¸ºå½“å‰é—®é¢˜ç»“æŸï¼Œå‡†å¤‡ä¸‹ä¸€ä¸ª
            # é™¤éAIæ˜ç¡®åœ¨æ‹‰å›æˆ–è€…è¿½é—® (è¿™éƒ¨åˆ†é€»è¾‘éœ€è¦åœ¨get_ai_responseçš„promptä¸­ç”±AIè‡ªå·±åˆ¤æ–­å¹¶è¾“å‡º)
            if st.session_state.current_question_index < TOTAL_QUESTIONS:
                # åªæœ‰å½“AIçš„å›å¤ä¸æ˜¯æ˜æ˜¾çš„æ‹‰å›æˆ–è¿½é—®æ—¶ï¼Œæ‰å¢åŠ ç´¢å¼•
                # è¿™ä¸ªåˆ¤æ–­æ¯”è¾ƒå¤æ‚ï¼Œæš‚æ—¶å‡è®¾AIä¼šæ­£ç¡®æå‡ºä¸‹ä¸€ä¸ªé—®é¢˜æˆ–æ˜ç¡®æŒ‡ç¤ºç»“æŸ
                # æˆ‘ä»¬éœ€è¦åœ¨ system prompt ä¸­è®©AIæ˜ç¡®å®ƒæ˜¯å¦æå‡ºäº†ä¸‹ä¸€ä¸ªé—®é¢˜
                # æˆ–è€…ï¼ŒAIçš„å›å¤ä¸­åŒ…å«ç‰¹å®šæ ‡è®°æ¥æŒ‡ç¤ºæ˜¯å¦è¿›å…¥ä¸‹ä¸€ä¸ªé—®é¢˜

                # **æ›´ç®€å•çš„åšæ³•**: ç›¸ä¿¡AIä¼šéµå¾ªæŒ‡ä»¤ï¼Œå¦‚æœå®ƒæ²¡æ‹‰å›ï¼Œé‚£ä¹ˆå®ƒå°±æ˜¯è¦æä¸‹ä¸€ä¸ªé—®é¢˜æˆ–ç»“æŸäº†
                # æˆ‘ä»¬ä¸»è¦é  `current_question_index` æ¥æ§åˆ¶
                st.session_state.current_question_index += 1

            if st.session_state.current_question_index > TOTAL_QUESTIONS:
                st.session_state.interaction_phase = "final_report"
        else:
            # å¦‚æœAIæ²¡æœ‰å›å¤ï¼ˆæ¯”å¦‚APIé”™è¯¯ï¼‰ï¼Œä¹Ÿæ˜¾ç¤ºä¸€æ¡æ¶ˆæ¯
            st.session_state.history.append({"role": "assistant", "content": "æŠ±æ­‰ï¼Œæˆ‘æš‚æ—¶æ— æ³•å›åº”ï¼Œè¯·ç¨åå†è¯•ã€‚"})

        st.rerun()

# 4. ç”Ÿæˆå¹¶æ˜¾ç¤ºæŠ¥å‘Š
if st.session_state.interaction_phase == "final_report" and not st.session_state.report_generated:
    st.info("æ‰€æœ‰é—®é¢˜å·²å›ç­”å®Œæ¯•ï¼Œæ­£åœ¨ä¸ºæ‚¨ç”Ÿæˆåˆæ­¥æŠ¥å‘Š...")

    full_transcript_for_report = "\n".join(
        [f"{('ç”¨æˆ·' if m['role'] == 'user' else 'AI')}: {m['content']}" for m in st.session_state.history])

    with st.spinner("æŠ¥å‘Šç”Ÿæˆä¸­..."):
        report_content = get_ai_response(
            phase="final_report",
            full_transcript=full_transcript_for_report
        )

    if report_content:
        st.session_state.report_generated = True
        # ç›´æ¥æ˜¾ç¤ºæŠ¥å‘Šï¼Œå› ä¸ºAIè¢«æŒ‡ç¤ºç›´æ¥è¾“å‡ºMarkdown
        st.markdown("---")
        st.subheader("åˆæ­¥äººç”Ÿè„šæœ¬æ¢ç´¢æŠ¥å‘Š")
        st.markdown(report_content)
        st.success("æŠ¥å‘Šç”Ÿæˆå®Œæ¯•ï¼è¯·æ³¨æ„ï¼Œè¿™ä»…ä¸ºåˆæ­¥æ¢ç´¢ï¼Œéä¸“ä¸šè¯Šæ–­ã€‚")
        # st.session_state.history.append({"role": "assistant", "content": report_content}) # çœ‹æ˜¯å¦éœ€è¦æŠŠæŠ¥å‘Šä¹ŸåŠ å…¥å†å²
    else:
        st.error("æŠ±æ­‰ï¼Œç”ŸæˆæŠ¥å‘Šæ—¶é‡åˆ°é—®é¢˜ã€‚")

    # æ·»åŠ é‡æ–°å¼€å§‹æŒ‰é’®
    if st.button("é‡æ–°å¼€å§‹æ¢ç´¢"):
        for key in list(st.session_state.keys()):
            del st.session_state[key]
        st.rerun()