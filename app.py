import os, json, streamlit as st
from openai import OpenAI, RequestsTransport
from utils.diagnose import diagnose

# ---------- ä»£ç†ï¼ˆå¯é€‰ï¼‰ ----------
# å¦‚æœä½ æœ¬æœºæœ‰ Clash / V2RayN ç­‰æœ¬åœ° HTTP ä»£ç†ï¼Œå°±æŠŠ PROXY_URL æ”¹æˆå¯¹åº”ç«¯å£ï¼›
# æ²¡æœ‰ä»£ç†æˆ–èƒ½ç›´è¿ OpenAIï¼Œå°±ç•™ç©ºå­—ç¬¦ä¸² ""ã€‚
PROXY_URL = "http://127.0.0.1:7890"    # â† æ”¹æˆè‡ªå·±çš„ HTTP ä»£ç†ç«¯å£ï¼Œæ²¡ç”¨å°±è®¾ä¸º ""

_http_client = RequestsHTTPClient(
    proxies={"http": PROXY_URL, "https": PROXY_URL} if PROXY_URL else None
)

# ---------- OpenAI å®¢æˆ·ç«¯ ----------
client = OpenAI(
    api_key=os.getenv("OPENAI_API_KEY"),
    http_client=_http_client,
    timeout=60,
    max_retries=3,
)

# ---------- Streamlit é¡µé¢ ----------
st.set_page_config(page_title="äººç”Ÿè„šæœ¬Â·åŠ¨æ€æé—®", layout="centered")
st.title("äººç”Ÿè„šæœ¬æ¢ç´¢ Demo ğŸŒ€")

MAX_Q = 30

SYSTEM_PROMPT = """
ä½ æ˜¯åŸºäºåŸƒé‡Œå…‹Â·ä¼¯æ©ã€Šäººç”Ÿè„šæœ¬ã€‹ç†è®ºçš„è„šæœ¬æ¢ç´¢ AIï¼Œç›®æ ‡æ˜¯åœ¨ä¸€æ¬¡å¯¹è¯é‡Œ
ç”Ÿæˆå¹¶æé—® 3â€“30 ä¸ªé—®é¢˜ï¼Œå¼•å¯¼ç”¨æˆ·æè¿°
â‘  ç«¥å¹´ç¦æ­¢ä»¤ / é©±åŠ¨åŠ› â‘¡ ç”Ÿæ´»ç«‹åœº â‘¢ è„šæœ¬è“å›¾ã€‚

ã€è§„åˆ™ã€‘
1. æ¯æ¬¡ä»…è¿”å› ONE questionï¼Œæ ¼å¼ JSONï¼š{{"question": "è¿™é‡Œå†™é—®é¢˜"}}ã€‚
2. é—®é¢˜ç”¨ä¸­æ–‡ï¼Œå…·ä½“ç”ŸåŠ¨ï¼Œé¿å…å¿ƒç†å­¦è¡Œè¯ã€‚
3. ä¸é‡å¤ä¸»é¢˜ï¼Œå¯æ ¹æ®ç”¨æˆ·ä¸Šä¸€æ¬¡å›ç­”æ·±æŒ–ç»†èŠ‚ã€‚
4. è‹¥å·²è¾¾åˆ° {max_q} é¢˜ï¼Œè¿”å› {{"question": "__END__"}}ã€‚
""".strip()

# ---------- åˆå§‹åŒ–ä¼šè¯çŠ¶æ€ ----------
if "history" not in st.session_state:
    st.session_state.history = [
        {"role": "assistant", "content": "ä½ å¥½ï¼æˆ‘æ˜¯è„šæœ¬æ¢ç´¢ä¼™ä¼´ ECHOï¼Œç°åœ¨æˆ‘ä»¬å¼€å§‹ã€‚"}
    ]
    st.session_state.q_count = 0

# ---------- æ˜¾ç¤ºå†å² ----------
for m in st.session_state.history:
    with st.chat_message(m["role"]):
        st.markdown(m["content"])

# ---------- è¾“å…¥æ¡† ----------
user_text = st.chat_input(
    "è¯·è¾“å…¥â€¦",
    disabled=st.session_state.q_count >= MAX_Q
)

# ---------- å¤„ç†ç”¨æˆ·è¾“å…¥ ----------
if user_text:
    # æ˜¾ç¤ºå¹¶ä¿å­˜ç”¨æˆ·æ¶ˆæ¯
    st.chat_message("user").markdown(user_text)
    st.session_state.history.append({"role": "user", "content": user_text})

    # ç»„ç»‡ä¸Šä¸‹æ–‡ï¼šsystem æç¤º + æœ€è¿‘ 12 æ¡å¯¹è¯
    ctx = [{"role": "system", "content": SYSTEM_PROMPT.format(max_q=MAX_Q)}]
    ctx += st.session_state.history[-12:]

    # è°ƒ OpenAI æ‹¿ä¸‹ä¸€é¢˜
    try:
        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=ctx,
            temperature=0.7,
        )
    except APIConnectionError as e:
        st.error("ğŸš§ æ— æ³•è¿æ¥ OpenAIï¼Œæ£€æŸ¥ç½‘ç»œ/ä»£ç†åé‡è¯•ã€‚\n\n" + str(e))
        st.stop()

    raw = resp.choices[0].message.content.strip()

    # è§£æ
    try:
        next_q = json.loads(raw)["question"].strip()
    except Exception:
        next_q = "__PARSE_ERROR__"

    # å¤„ç†ç»“æœ
    if next_q and next_q not in ("__END__", "__PARSE_ERROR__"):
        st.session_state.q_count += 1
        st.chat_message("assistant").markdown(next_q)
        st.session_state.history.append({"role": "assistant", "content": next_q})
    else:
        st.session_state.q_count = MAX_Q
        st.session_state.history.append(
            {"role": "assistant",
             "content": "æ„Ÿè°¢å›ç­”ï¼Œé—®é¢˜ç»“æŸï¼ç‚¹å‡»ä¸‹æ–¹æŒ‰é’®ç”Ÿæˆåˆæ­¥æŠ¥å‘Šã€‚"}
        )
    st.rerun()

# ---------- ç”ŸæˆæŠ¥å‘Š ----------
if st.session_state.q_count >= MAX_Q:
    if st.button("ç”ŸæˆæŠ¥å‘Š"):
        answers = [m for m in st.session_state.history if m["role"] == "user"]
        # mock æ˜ å°„é”®åæ–¹ä¾¿ç¤ºä¾‹ diagnose
        fake_pairs = [{"q": "inj_x", "a": a["content"]} for a in answers]
        data = diagnose(fake_pairs)
        st.markdown(f"""
### åˆæ­¥è„šæœ¬æŠ¥å‘Š
**è„šæœ¬å€¾å‘**ï¼š{data['summary']}  
Injunction çº¿ç´¢ï¼š{data['inj_cnt']}  
Driver çº¿ç´¢ï¼š{data['driver_cnt']}  

*(ä»…ä¾›æ¢ç´¢ï¼Œéä¸“ä¸šè¯Šæ–­)*
""")
